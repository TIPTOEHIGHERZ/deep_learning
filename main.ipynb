{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-05T04:59:13.377748600Z",
     "start_time": "2024-08-05T04:59:13.317833300Z"
    }
   },
   "outputs": [],
   "source": [
    "import torchtext\n",
    "from torchtext.datasets import Multi30k\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import itertools\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def tokenize(iterator):\n",
    "    tokenized_src_sentence = list()\n",
    "    tokenized_dst_sentence = list()\n",
    "    \n",
    "    for dst_sentence, src_sentence in iterator:\n",
    "        tokenized_src_sentence.append(src_sentence.split())\n",
    "        tokenized_dst_sentence.append(dst_sentence.split())\n",
    "    \n",
    "    return tokenized_src_sentence, tokenized_dst_sentence"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-05T04:59:13.377748600Z",
     "start_time": "2024-08-05T04:59:13.338834900Z"
    }
   },
   "id": "4fcd5a95961053cf"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "root = './data'\n",
    "batch_size = 128\n",
    "\n",
    "train_data = Multi30k(root, split='train')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-05T04:59:13.378744400Z",
     "start_time": "2024-08-05T04:59:13.353763300Z"
    }
   },
   "id": "2bd472cb6cfd1afb"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    def __init__(self, language):\n",
    "        assert language in ['en_core_web_sm', 'de_core_news_sm']\n",
    "        \n",
    "        self.tokenizer = get_tokenizer('spacy', language=language)\n",
    "        self.language = language\n",
    "        return\n",
    "    \n",
    "    def get_tokens(self, iterator):\n",
    "        if self.language == 'en_core_web_sm':\n",
    "            return [self.tokenizer(sentence) for _, sentence in iterator]\n",
    "        elif self.language == 'de_core_news_sm':\n",
    "            return [self.tokenizer(sentence) for sentence, _ in iterator]\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def __call__(self, iterator):\n",
    "        return self.get_tokens(iterator)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-05T04:59:13.413601500Z",
     "start_time": "2024-08-05T04:59:13.370128300Z"
    }
   },
   "id": "6da384ffd6a30718"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "def collate_fn(data: list):\n",
    "    x = list()\n",
    "    y = list()\n",
    "    for x_, y_ in data:\n",
    "        x.append(x_)\n",
    "        y.append(y_)\n",
    "        \n",
    "    return torch.tensor(x), torch.tensor(y)\n",
    "\n",
    "\n",
    "class SentenceLoader:\n",
    "    tokens_en: list = None\n",
    "    tokens_ge: list = None\n",
    "    vocab_en: torchtext.vocab.Vocab = None\n",
    "    vocab_ge: torchtext.vocab.Vocab = None\n",
    "    numeral_token_en: list = None\n",
    "    numeral_token_ge: list = None\n",
    "    def __init__(self, data_iterator, shuffle=False, batch_size=1, device='cuda'):\n",
    "        self.tokenizer_en = Tokenizer('en_core_web_sm')\n",
    "        self.tokenizer_ge = Tokenizer('de_core_news_sm')\n",
    "        self.data = list(data_iterator)\n",
    "        \n",
    "        self.make_tokens()\n",
    "        self.build_vocab()\n",
    "        \n",
    "        self.numeral_token_en = self.text_transform(self.tokens_en, 'en')\n",
    "        self.numeral_token_en = self.text_pad(self.numeral_token_en, 512, 'en')\n",
    "        self.numeral_token_ge = self.text_transform(self.tokens_ge, 'ge')\n",
    "        self.numeral_token_ge = self.text_pad(self.numeral_token_ge, 512, 'ge')\n",
    "        \n",
    "        self.data_loader = torch.utils.data.DataLoader(list(zip(self.numeral_token_en, self.numeral_token_ge)),\n",
    "                                                       batch_size=batch_size,\n",
    "                                                       shuffle=shuffle,\n",
    "                                                       collate_fn=collate_fn)\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def make_tokens(self):\n",
    "        self.tokens_en = self.tokenizer_en(self.data)\n",
    "        self.tokens_ge = self.tokenizer_ge(self.data)\n",
    "        \n",
    "        return self.tokens_en, self.tokens_ge\n",
    "    \n",
    "    def build_vocab(self, specials=['<unk>', '<BOS>', '<EOS>', '<PAD>']):\n",
    "        self.vocab_en = torchtext.vocab.build_vocab_from_iterator(self.tokens_en, specials=specials)\n",
    "        self.vocab_en.set_default_index(self.vocab_en['<unk>'])\n",
    "        self.vocab_ge = torchtext.vocab.build_vocab_from_iterator(self.tokens_ge, specials=specials)\n",
    "        self.vocab_ge.set_default_index(self.vocab_ge['<unk>'])\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def text_transform(self, sentence_list: list, language: str):\n",
    "        if language == 'en':     \n",
    "            return [[self.vocab_en['<BOS>']] + [self.vocab_en[token] for token in tokens] + [self.vocab_en['<EOS>']]\n",
    "                    for tokens in sentence_list]\n",
    "        elif language == 'ge':\n",
    "            return [[self.vocab_ge['<BOS>']] + [self.vocab_ge[token] for token in tokens] + [self.vocab_ge['<EOS>']] \n",
    "                    for tokens in sentence_list]\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def text_pad(self, tokens: list, fixed_length: int, language: str):\n",
    "        if language == 'en':\n",
    "            vocab = self.vocab_en\n",
    "        elif language == 'ge':\n",
    "            vocab = self.vocab_ge\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "        for token in tokens:\n",
    "            if fixed_length < len(token):\n",
    "                print('fixed_length too small')\n",
    "                raise ValueError\n",
    "            token += (fixed_length - len(token)) * [vocab['<PAD>']]\n",
    "        \n",
    "        return tokens\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return iter(self.data_loader)\n",
    "    \n",
    "    def get_batch(self, index):\n",
    "        return next(itertools.islice(iter(self.data_loader), index, index + 1))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-05T05:11:22.285056Z",
     "start_time": "2024-08-05T05:11:22.244564Z"
    }
   },
   "id": "22d7b1ed133d9454"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "sentence_loader = SentenceLoader(train_data, batch_size=32)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-05T05:11:26.578725700Z",
     "start_time": "2024-08-05T05:11:23.694844500Z"
    }
   },
   "id": "92961bb13d6bf728"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "iterator = iter(sentence_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-05T05:11:38.113806300Z",
     "start_time": "2024-08-05T05:11:38.027040900Z"
    }
   },
   "id": "51db34979a3b48e7"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "en, ge = next(iterator)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-05T05:11:40.096812600Z",
     "start_time": "2024-08-05T05:11:40.049501600Z"
    }
   },
   "id": "67f5d8adeb23964b"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 512])\n"
     ]
    }
   ],
   "source": [
    "print(en.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-05T05:11:41.203058200Z",
     "start_time": "2024-08-05T05:11:41.162676200Z"
    }
   },
   "id": "a85568c4b4948706"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
